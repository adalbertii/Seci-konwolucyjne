{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Seci-konwolucyjne/blob/main/keras_convolutional_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv-vG0yB3rDC"
      },
      "source": [
        "\n",
        "**Educational Friday\n",
        "\n",
        "---\n",
        "Developed by Wojciech Michalski\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Construction of convolutional neural networks - binary classification case\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Using the Keras library\n",
        "\n",
        "> Convolutional networks learn local patterns. The patterns recognized by the convolutional network are independent of their position in the image.\n",
        "\n",
        " > The advantage of CNN is the ability to teach a spatial hierarchy of patterns. The first layers learn small local patterns, such as edges, and subsequent layers will learn larger structures consisting of elements recognized by the initial layers.\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCz9aJm_LVU5"
      },
      "source": [
        "### Importing required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Io73Pv93qTF",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3IHY7rPajR6"
      },
      "source": [
        "### Download training and test data\n",
        "We will download the data from Amazon S3 storage.\n",
        "\n",
        "The name of the bucket is: `ml-repository-crackers`.\n",
        "\n",
        "The zipped file `dogs-vs-cats.zip` is just over 812 MB and is stored in the EU (Ireland) region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBFL23UOadMi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm -rf /content/*\n",
        "\n",
        "pwd\n",
        "wget --output-document=cats_and_dogs.zip --quiet https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/cats_and_dogs/dogs-vs-cats.zip\n",
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERChigfFVxoV"
      },
      "source": [
        "# Data unpacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsrSefiQC0Vv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "unzip cats_and_dogs.zip\n",
        "# rm -rf cats_and_dogs.zip\n",
        "\n",
        "rm -rf sampleSubmission.csv\n",
        "\n",
        "unzip -q train.zip -d /content/kaggle_original_data\n",
        "rm -rf train.zip\n",
        "cp /content/kaggle_original_data/train/* /content/kaggle_original_data/\n",
        "rm -rf /content/kaggle_original_data/train\n",
        "\n",
        "unzip -q /content/test1.zip\n",
        "# rm -rf test1.zip\n",
        "# rm -rf cats_and_dogs.zip\n",
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuBQIzV_Mxb9"
      },
      "source": [
        "# Preparation of the appropriate directory structure\n",
        "\n",
        "The data will be stored in the directory:\n",
        "\n",
        "> `/content/cats_and_dogs`\n",
        "\n",
        "We will divide this directory into three subdirectories:\n",
        " * train\n",
        " * valid\n",
        " * test\n",
        "\n",
        "In the training set, we will put 2,000 samples (1,000 photos of dogs and 1,000 photos of cats), 1,000 samples (500 photos of dogs and 500 photos of cats) will go to the validation set, and the last 1,000 samples (500 photos of dogs and 500 photos of cats) will go to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "S38WV5wJMxb-"
      },
      "outputs": [],
      "source": [
        "\n",
        "original_dataset_dir = '/content/kaggle_original_data'\n",
        "\n",
        "base_dir = '/content/cats_and_dogs'\n",
        "\n",
        "if not os.path.exists(base_dir):\n",
        "    os.mkdir(base_dir)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "valid_dir = os.path.join(base_dir, 'valid')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "for directory in (train_dir, valid_dir, test_dir):\n",
        "    if not os.path.exists(directory):\n",
        "        os.mkdir(directory)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "valid_cats_dir = os.path.join(valid_dir, 'cats')\n",
        "valid_dogs_dir = os.path.join(valid_dir, 'dogs')\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "dirs = [train_cats_dir, train_dogs_dir, valid_cats_dir, valid_dogs_dir, test_cats_dir, test_dogs_dir]\n",
        "\n",
        "for directory in dirs:\n",
        "    if not os.path.exists(directory):\n",
        "        os.mkdir(directory)\n",
        "\n",
        "\n",
        "# separate the fhotos\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(valid_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(valid_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX2i4m5jMxb_"
      },
      "source": [
        "Checking the correctness of the division\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "SmCEJ_xMMxb_"
      },
      "outputs": [],
      "source": [
        "print('Number of cats - training set', len(os.listdir(train_cats_dir)))\n",
        "print('Number of cats - validation set', len(os.listdir(valid_cats_dir)))\n",
        "print('Number of cats - test set', len(os.listdir(test_cats_dir)))\n",
        "\n",
        "print('Number of dogs - training set', len(os.listdir(train_dogs_dir)))\n",
        "print('Number of dogs - validation set', len(os.listdir(valid_dogs_dir)))\n",
        "print('Number of dogs - test set', len(os.listdir(test_dogs_dir)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLAharS2MxcA"
      },
      "source": [
        "### Look at the sample pictures - cats and dogs\n",
        "> Tip: Use the slider on the right to select a different image index."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import PIL.Image"
      ],
      "metadata": {
        "id": "VTYauxWTV2B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 438 #@param {type:'slider', min:0, max:999}\n",
        "img_path = '/content/cats_and_dogs/train/cats/cat.' + str(index) +'.jpg'\n",
        "PIL.Image.open(img_path)"
      ],
      "metadata": {
        "id": "GJ6UA_yMZtSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 438 #@param {type:'slider', min:0, max:999}\n",
        "img_path = '/content/cats_and_dogs/train/dogs/dog.' + str(index) +'.jpg'\n",
        "PIL.Image.open(img_path)"
      ],
      "metadata": {
        "id": "bftleaN4b2Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx4Y5psmWF0g"
      },
      "source": [
        "### Helpful function definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqAjuvecWEr3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def make_accuracy_plot(history):\n",
        "    \"\"\"\n",
        "    The function returns the accuracy plot of the model on the training set\n",
        "    and validation.\n",
        "    \"\"\"\n",
        "    acc, val_acc = history.history['accuracy'], history.history['val_accuracy']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(epochs, acc, label='Accuracy of training', marker='o')\n",
        "    plt.plot(epochs, val_acc, label='Validation accuracy', marker='o')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy of training and validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "def make_loss_plot(history):\n",
        "    \"\"\"\n",
        "    The function returns the loss plot of the model on the training set\n",
        "    and validation.\n",
        "    \"\"\"\n",
        "    loss, val_loss = history.history['loss'], history.history['val_loss']\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(epochs, loss, label='Training loss', marker='o')\n",
        "    plt.plot(epochs, val_loss, label='Validation loss', marker='o')\n",
        "    plt.legend()\n",
        "    plt.title('Loss of training and validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nws0bIBL1gd"
      },
      "source": [
        "### Building the model\n",
        "\n",
        "\n",
        "> The Conv2D layer is a convolution layer in which at least three parameters must be specified:\n",
        "- the number of filters that will extract the features,\n",
        "- the size of the kernel (the size of the convolution window, usually 3x3 or 5x5) and\n",
        "- the activation function (the most commonly used `relu` function).\n",
        "\n",
        "In addition, in the first layer, you must specify the `input_shape` parameter, which takes the size of the input data. In our case `(150, 150, 3)`. The first two values ​​determine the width and height of the image, while the third determines the color depth, in this case 3.\n",
        "\n",
        "> The MaxPooling2D layer is a scaling operation. In simple terms, it consists in reducing dimensionality by passing through the image with extraction windows that return the maximum observed value in a given window (usually a 2x2 window size, with a shift step of 2), thus helping to reduce the size of the input data to the next layer by half, which significantly speeds up the process learning.\n",
        "\n",
        "> The Flatten layer flattens our data in order to combine them with dense layers at the end of building the model. The last activation function will be the `sigmoid` function, which will return the probabilities of the image belonging to a particular class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JufpzuvdAiTO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=512, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWx8UsMAiMs3"
      },
      "source": [
        "\n",
        "### Model compilation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG_InvpTL_yc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXlUrOHON2u1"
      },
      "source": [
        "### Step 5 - Processing the data into the model\n",
        "\n",
        "Since our data is non-standardized (different sizes of images), we need to process it so that it is presented in the form of tensors of floating point values ​​(float). Our data is currently in JPG files. In the data processing process, the `ImageDataGenerator` class built into `Keras` will help us. All images from the training and validation sets will be scaled to 150x150 pixels.\n",
        "\n",
        "#### In short, we will do:\n",
        "- upload files in JPG format\n",
        "- decode JPG format to pixel grid in RGB format\n",
        "- save the data in the tensor format of floating point numbers\n",
        "- scale the pixel values ​​to the range [0, 1] (neural networks are better at dealing with small input values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHZHae9BM7c5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# we scale all images by a factor of 1/255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_jQm34zjMXe"
      },
      "source": [
        "### Checking the correct shape of the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBA_9OzoOQzG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('Batch data shape:', data_batch.shape)\n",
        "    print('Batch data label shape:', labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unVmKEBXPj5a"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We will save the trained model to the file `cats_and_dogs_small_1.h5`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLDcqvbyPTLR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "tic = time.time()\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                             steps_per_epoch=100,\n",
        "                             epochs=20,\n",
        "                             validation_data=valid_generator,\n",
        "                             validation_steps=50)\n",
        "\n",
        "toc = time.time()\n",
        "print('Processing time: {}'.format(toc - tic))\n",
        "model.save('wmi_small_model_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl97uLiCjkyk"
      },
      "source": [
        "### Training and validation accuracy graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7wSORjtV5dB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_accuracy_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R64tAD3WSwo"
      },
      "source": [
        "### Training and validation loss graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6m_Ou4oWakC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_loss_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIXWBqY9meoZ"
      },
      "source": [
        "### Data Augmentation\n",
        "\n",
        "Particularly useful in cases of insufficient training data. It consists in various transformations of the input data through operations such as cropping, rotation or zooming in order to generate new input data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVdgXSGdrN-I"
      },
      "source": [
        "### Building a model using images generated using data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM8mkyC-ouAV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(units=512, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M3Cuasmq-Qb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "# we do not modify the validation data!!!\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTS5PTSNlZBI"
      },
      "source": [
        "\n",
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmWpD_ikrcJG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                             steps_per_epoch=100,\n",
        "                             epochs=20,    # 100\n",
        "                             validation_data=valid_generator,\n",
        "                             validation_steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71tgbWR9ftrZ"
      },
      "source": [
        "### Save model to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjtiOfNysX3p",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model.save('wmi_small_model_2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlYVAa8TZkHd"
      },
      "source": [
        "### Training and validation accuracy graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzujYf4IZhMR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_accuracy_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikec0EjwZrX9"
      },
      "source": [
        "### Training and validation loss graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO9dX4rWZviB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_loss_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQDMs5Cpvq8F"
      },
      "source": [
        "### Transfer Learning -\n",
        "\n",
        "is based on the use of an already overtrained model, usually on a very large input set,\n",
        "We will use the architecture of the VGG16 model (containing 16 layers) trained on the `Imagenet` set.\n",
        "The Imagenet collection consists of 1.4 million images divided into 1000 classes, which also include different breeds of dogs and cats.\n",
        "The finished model is available in the Keras library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru1W8d54vyWN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                 include_top=False,    # whether to join the upper part of the network\n",
        "                 input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IittEKDRARj"
      },
      "source": [
        "## Feature extraction with data augmentation\n",
        "\n",
        "We will use the advantages of Transfer Learning as well as data augmentation techniques. We will add the last three layers to the downloaded model: a Flatten layer and two dense layers (Dense)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcDbCMeeGDi_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=256, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQpBsq0-Z5cb"
      },
      "source": [
        "### Train the model from start to finish with a frozen convolutional base\n",
        "\n",
        "We will now freeze the weights of the VGG16 network to prevent these weights from being updated in the training process. If we did not, the features that the model learned could be modified during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBJ74WrMRk-E",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRILKZnQMxcN"
      },
      "source": [
        "### Data augmentation stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjKvwQDMSFk4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "\n",
        "# validation data cannot be modified!!!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')\n",
        "valid_generator = test_datagen.flow_from_directory(valid_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPVVGKJ-MxcS"
      },
      "source": [
        "### Compilation and training of an extended model (excluding convolution layers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghj-tJrVaHpC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                             steps_per_epoch=100,\n",
        "                             epochs=50,\n",
        "                             validation_data=valid_generator,\n",
        "                             validation_steps=50,\n",
        "                             verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rm3UdHjMxcS"
      },
      "source": [
        "### Accuracy Level Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tStcwaWvap6J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_accuracy_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd4I33L_MxcT"
      },
      "source": [
        "### Loss function distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EstZYFs3b1fJ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_loss_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyk6KBsYcDgn"
      },
      "source": [
        "### Tuning\n",
        "\n",
        "\n",
        "\n",
        "This technique consists in 'unfreezing' several upper layers of the frozen base of the model. We will tune the last three convolutional layers (`block5_conv1, block5_conv2, block5_conv3`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEnttk9Vb6iI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        "                 include_top=False,    # whether to include the upper part of the network\n",
        "                 input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whOk41TNg3Ef",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "def print_layers(model):\n",
        "    for layer in model.layers:\n",
        "        print('layer_name: {:12}, trainable: {}'.format(layer.name, layer.trainable))\n",
        "\n",
        "print_layers(conv_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiqoEQceizkN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print_layers(conv_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxOQkQ-QkPYO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=256, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SmTBzxTxHbL"
      },
      "source": [
        "\n",
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xifSIc88kp3y",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                             steps_per_epoch=100,\n",
        "                             epochs=50,\n",
        "                             validation_data=valid_generator,\n",
        "                             validation_steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KArh2CTAk5iR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_accuracy_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS_SoqvzlCJE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "make_loss_plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkoqm5DxPyH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-fjbzKplT6D",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(150, 150),\n",
        "                                                 batch_size=20,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('Testing Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymmUQgdJmrAa"
      },
      "source": [
        "##Conclusions\n",
        "\n",
        "* Convolutional neural networks are the best machine learning models for image processing tasks\n",
        "* Convolutional networks can be trained even on small data sets, for this purpose data augmentation and transfer learning are helpful (example: medical photos)\n",
        "* The possibility of using transfer learning allows you to train models in a much shorter time with much greater efficiency of such a model compared to a model based only on the data we have\n",
        "* Tuning techniques allow you to adapt previously learned models to our problem, which should in fact lead to improved model performance\n",
        "* As it is commonly believed about neural networks as \"black boxes\", in the case of convolutional networks, the individual stages of the network's operation are easy to visualize.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}